import json
import pickle
from pathlib import Path

import numpy as np
import streamlit as st
import torch

from src.models import ACTPuzzleSolver
from src.universal_transformer import UniversalTransformerPuzzleSolver

MAZE_CHARSET = "# SGo"

st.set_page_config(page_title="Checkpoint Inference Viewer", layout="wide")
st.title("ğŸ§© Checkpoint Inference Viewer")
st.caption("ì €ì¥ëœ ì²´í¬í¬ì¸íŠ¸ë¡œ í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ 1ê°œë¥¼ ì¶”ë¡ í•´ ì…ë ¥/ì •ë‹µ/ì˜ˆì¸¡ì„ ë¹„êµí•©ë‹ˆë‹¤.")




def load_model_from_checkpoint(ckpt_path: Path):
    """Load checkpoint compatibly across torch/lightning versions.

    - Forces `weights_only=False` for trusted checkpoints (PyTorch 2.6 default changed).
    - Reconstructs model from saved hyper_parameters + state_dict.
    - Backfills legacy hparams key `lr_warmup_steps` -> `lr_warmup_epochs`.
    """
    try:
        checkpoint = torch.load(str(ckpt_path), map_location="cpu", weights_only=False)
    except TypeError:
        checkpoint = torch.load(str(ckpt_path), map_location="cpu")

    hparams = dict(checkpoint.get("hyper_parameters", {}))
    if "lr_warmup_steps" in hparams and "lr_warmup_epochs" not in hparams:
        hparams["lr_warmup_epochs"] = hparams.pop("lr_warmup_steps")

    model_type = hparams.get("model_type", "act_rnn")
    if model_type == "universal_transformer":
        model = UniversalTransformerPuzzleSolver(**hparams)
    else:
        model = ACTPuzzleSolver(**hparams)
    state_dict = checkpoint.get("state_dict")
    if state_dict is None:
        raise KeyError("Checkpointì— state_dictê°€ ì—†ìŠµë‹ˆë‹¤.")

    model.load_state_dict(state_dict, strict=True)
    model.eval()
    return model

def load_dataset_split(data_dir: Path, split: str):
    split_dir = data_dir / split
    inputs = np.load(split_dir / "all__inputs.npy", mmap_mode="r")
    labels = np.load(split_dir / "all__labels.npy", mmap_mode="r")
    meta = json.loads((split_dir / "dataset.json").read_text())
    return inputs, labels, meta


def infer_task(meta: dict, model) -> str:
    task_name = getattr(model, "task_name", None)
    if task_name in {"maze", "sudoku"}:
        return task_name
    if meta.get("seq_len") == 81:
        return "sudoku"
    return "maze"


def decode_grid(arr_1d: np.ndarray, task: str) -> list[list[str]]:
    values = arr_1d.astype(int)
    if task == "sudoku":
        side = 9
        grid = values.reshape(side, side)
        return [[str(max(v - 1, 0)) for v in row] for row in grid]

    side = int(np.sqrt(len(values)))
    chars = ["Â·"] + list(MAZE_CHARSET)
    grid = values.reshape(side, side)
    return [[chars[v] if 0 <= v < len(chars) else "?" for v in row] for row in grid]


def _cell_html(char: str) -> str:
    class_name = "maze-cell"
    content = ""
    if char == "#":
        class_name += " maze-wall"
    elif char == "S":
        class_name += " maze-start"
        content = "S"
    elif char == "G":
        class_name += " maze-goal"
        content = "G"
    elif char == "o":
        class_name += " maze-path"
        content = "o"
    elif char == "Â·":
        content = "Â·"
    elif char == "?":
        content = "?"
    else:
        content = "&nbsp;"
    return f"<div class='{class_name}'>{content}</div>"


def render_grid(title: str, grid: list[list[str]], *, key: str):
    st.markdown(f"**{title}**")

    cell_size_px = 18
    rows = len(grid)
    cols = len(grid[0]) if rows > 0 else 0
    html_cells = "".join(_cell_html(c) for row in grid for c in row)
    st.markdown(
        f"""
        <style>
            .maze-grid-{key} {{
                display: grid;
                grid-template-columns: repeat({cols}, {cell_size_px}px);
                grid-template-rows: repeat({rows}, {cell_size_px}px);
                gap: 1px;
                width: fit-content;
                padding: 4px;
                border: 1px solid #d9d9d9;
                background: #d9d9d9;
            }}
            .maze-grid-{key} .maze-cell {{
                width: {cell_size_px}px;
                height: {cell_size_px}px;
                display: flex;
                align-items: center;
                justify-content: center;
                background: #ffffff;
                color: #1f2937;
                font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, monospace;
                font-size: 12px;
                font-weight: 600;
                line-height: 1;
            }}
            .maze-grid-{key} .maze-wall {{
                background: #2f3542;
                color: transparent;
            }}
            .maze-grid-{key} .maze-start {{
                color: #047857;
            }}
            .maze-grid-{key} .maze-goal {{
                color: #b45309;
            }}
            .maze-grid-{key} .maze-path {{
                color: #1d4ed8;
            }}
        </style>
        <div class='maze-grid-{key}'>{html_cells}</div>
        """,
        unsafe_allow_html=True,
    )


with st.sidebar:
    st.header("ì…ë ¥")
    ckpt_path = Path(st.text_input("ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ", value="runs/checkpoints/last.ckpt")).expanduser()
    data_dir = Path(st.text_input("ë°ì´í„°ì…‹ ê²½ë¡œ", value="data/maze-30x30-hard-1k")).expanduser()
    split = st.selectbox("Split", ["test", "train"], index=0)

    sample_index = st.number_input("ìƒ˜í”Œ ì¸ë±ìŠ¤", min_value=0, value=0, step=1)
    run_button = st.button("ì¶”ë¡  ì‹¤í–‰", type="primary")

if not run_button:
    st.info("ì¢Œì¸¡ì—ì„œ ê²½ë¡œ/ìƒ˜í”Œì„ ì„ íƒí•˜ê³  'ì¶”ë¡  ì‹¤í–‰'ì„ ëˆ„ë¥´ì„¸ìš”.")
    st.stop()

if not ckpt_path.exists():
    st.error(f"ì²´í¬í¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {ckpt_path}")
    st.stop()

if not (data_dir / split).exists():
    st.error(f"ë°ì´í„° split ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {data_dir / split}")
    st.stop()

with st.spinner("ëª¨ë¸/ë°ì´í„° ë¡œë“œ ì¤‘..."):
    try:
        model = load_model_from_checkpoint(ckpt_path)
    except pickle.UnpicklingError as e:
        st.error("ì²´í¬í¬ì¸íŠ¸ ë¡œë”© ì‹¤íŒ¨ (weights_only ê´€ë ¨). ì‹ ë¢° ê°€ëŠ¥í•œ ì²´í¬í¬ì¸íŠ¸ë¼ë©´ weights_only=Falseë¡œ ë¡œë“œí•´ì•¼ í•©ë‹ˆë‹¤.")
        st.exception(e)
        st.stop()

    inputs, labels, meta = load_dataset_split(data_dir, split)
    if sample_index >= len(inputs):
        st.error(f"ìƒ˜í”Œ ì¸ë±ìŠ¤ ë²”ìœ„ë¥¼ ë²—ì–´ë‚¬ìŠµë‹ˆë‹¤. ìµœëŒ€ ì¸ë±ìŠ¤: {len(inputs) - 1}")
        st.stop()

    x = torch.from_numpy(np.array(inputs[sample_index])).long().unsqueeze(0)
    y = np.array(labels[sample_index]).astype(int)

    with torch.no_grad():
        logits, _, steps, _ = model(x)
        pred = torch.argmax(logits, dim=-1).squeeze(0).cpu().numpy().astype(int)

    task = infer_task(meta, model)

input_grid = decode_grid(np.array(inputs[sample_index]), task)
label_grid = decode_grid(y, task)
pred_grid = decode_grid(pred, task)

acc = float((pred == y).mean())
all_correct = bool((pred == y).all())

left, mid, right = st.columns(3)
with left:
    render_grid("ì…ë ¥", input_grid, key="input")
with mid:
    render_grid("ì •ë‹µ", label_grid, key="label")
with right:
    render_grid("ì˜ˆì¸¡", pred_grid, key="pred")

st.metric("ì…€ ì •í™•ë„", f"{acc:.4f}")
st.metric("í¼ì¦ ì™„ì „ ì •ë‹µ", "âœ…" if all_correct else "âŒ")
st.metric("í‰ê·  ì¶”ë¡  ìŠ¤í…", f"{float(steps.float().mean()):.2f}")
