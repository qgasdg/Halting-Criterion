import json
import pickle
from pathlib import Path

import numpy as np
import streamlit as st
import torch

from src.models import ACTPuzzleSolver

MAZE_CHARSET = "# SGo"

st.set_page_config(page_title="Checkpoint Inference Viewer", layout="wide")
st.title("ğŸ§© Checkpoint Inference Viewer")
st.caption("ì €ì¥ëœ ì²´í¬í¬ì¸íŠ¸ë¡œ í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ 1ê°œë¥¼ ì¶”ë¡ í•´ ì…ë ¥/ì •ë‹µ/ì˜ˆì¸¡ì„ ë¹„êµí•©ë‹ˆë‹¤.")




def load_model_from_checkpoint(ckpt_path: Path) -> ACTPuzzleSolver:
    """Load checkpoint compatibly across torch/lightning versions.

    - Forces `weights_only=False` for trusted checkpoints (PyTorch 2.6 default changed).
    - Reconstructs model from saved hyper_parameters + state_dict.
    - Backfills legacy hparams key `lr_warmup_steps` -> `lr_warmup_epochs`.
    """
    try:
        checkpoint = torch.load(str(ckpt_path), map_location="cpu", weights_only=False)
    except TypeError:
        checkpoint = torch.load(str(ckpt_path), map_location="cpu")

    hparams = dict(checkpoint.get("hyper_parameters", {}))
    if "lr_warmup_steps" in hparams and "lr_warmup_epochs" not in hparams:
        hparams["lr_warmup_epochs"] = hparams.pop("lr_warmup_steps")

    model = ACTPuzzleSolver(**hparams)
    state_dict = checkpoint.get("state_dict")
    if state_dict is None:
        raise KeyError("Checkpointì— state_dictê°€ ì—†ìŠµë‹ˆë‹¤.")

    model.load_state_dict(state_dict, strict=True)
    model.eval()
    return model

def load_dataset_split(data_dir: Path, split: str):
    split_dir = data_dir / split
    inputs = np.load(split_dir / "all__inputs.npy", mmap_mode="r")
    labels = np.load(split_dir / "all__labels.npy", mmap_mode="r")
    meta = json.loads((split_dir / "dataset.json").read_text())
    return inputs, labels, meta


def infer_task(meta: dict, model: ACTPuzzleSolver) -> str:
    task_name = getattr(model, "task_name", None)
    if task_name in {"maze", "sudoku"}:
        return task_name
    if meta.get("seq_len") == 81:
        return "sudoku"
    return "maze"


def decode_grid(arr_1d: np.ndarray, task: str) -> list[list[str]]:
    values = arr_1d.astype(int)
    if task == "sudoku":
        side = 9
        grid = values.reshape(side, side)
        return [[str(max(v - 1, 0)) for v in row] for row in grid]

    side = int(np.sqrt(len(values)))
    chars = ["Â·"] + list(MAZE_CHARSET)
    grid = values.reshape(side, side)
    return [[chars[v] if 0 <= v < len(chars) else "?" for v in row] for row in grid]


def render_grid(title: str, grid: list[list[str]]):
    st.markdown(f"**{title}**")
    st.table(grid)


with st.sidebar:
    st.header("ì…ë ¥")
    ckpt_path = Path(st.text_input("ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ", value="runs/checkpoints/last.ckpt")).expanduser()
    data_dir = Path(st.text_input("ë°ì´í„°ì…‹ ê²½ë¡œ", value="data/maze-30x30-hard-1k")).expanduser()
    split = st.selectbox("Split", ["test", "train"], index=0)

    sample_index = st.number_input("ìƒ˜í”Œ ì¸ë±ìŠ¤", min_value=0, value=0, step=1)
    run_button = st.button("ì¶”ë¡  ì‹¤í–‰", type="primary")

if not run_button:
    st.info("ì¢Œì¸¡ì—ì„œ ê²½ë¡œ/ìƒ˜í”Œì„ ì„ íƒí•˜ê³  'ì¶”ë¡  ì‹¤í–‰'ì„ ëˆ„ë¥´ì„¸ìš”.")
    st.stop()

if not ckpt_path.exists():
    st.error(f"ì²´í¬í¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {ckpt_path}")
    st.stop()

if not (data_dir / split).exists():
    st.error(f"ë°ì´í„° split ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {data_dir / split}")
    st.stop()

with st.spinner("ëª¨ë¸/ë°ì´í„° ë¡œë“œ ì¤‘..."):
    try:
        model = load_model_from_checkpoint(ckpt_path)
    except pickle.UnpicklingError as e:
        st.error("ì²´í¬í¬ì¸íŠ¸ ë¡œë”© ì‹¤íŒ¨ (weights_only ê´€ë ¨). ì‹ ë¢° ê°€ëŠ¥í•œ ì²´í¬í¬ì¸íŠ¸ë¼ë©´ weights_only=Falseë¡œ ë¡œë“œí•´ì•¼ í•©ë‹ˆë‹¤.")
        st.exception(e)
        st.stop()

    inputs, labels, meta = load_dataset_split(data_dir, split)
    if sample_index >= len(inputs):
        st.error(f"ìƒ˜í”Œ ì¸ë±ìŠ¤ ë²”ìœ„ë¥¼ ë²—ì–´ë‚¬ìŠµë‹ˆë‹¤. ìµœëŒ€ ì¸ë±ìŠ¤: {len(inputs) - 1}")
        st.stop()

    x = torch.from_numpy(np.array(inputs[sample_index])).long().unsqueeze(0)
    y = np.array(labels[sample_index]).astype(int)

    with torch.no_grad():
        logits, _, steps, _ = model(x)
        pred = torch.argmax(logits, dim=-1).squeeze(0).cpu().numpy().astype(int)

    task = infer_task(meta, model)

input_grid = decode_grid(np.array(inputs[sample_index]), task)
label_grid = decode_grid(y, task)
pred_grid = decode_grid(pred, task)

acc = float((pred == y).mean())
all_correct = bool((pred == y).all())

left, mid, right = st.columns(3)
with left:
    render_grid("ì…ë ¥", input_grid)
with mid:
    render_grid("ì •ë‹µ", label_grid)
with right:
    render_grid("ì˜ˆì¸¡", pred_grid)

st.metric("ì…€ ì •í™•ë„", f"{acc:.4f}")
st.metric("í¼ì¦ ì™„ì „ ì •ë‹µ", "âœ…" if all_correct else "âŒ")
st.metric("í‰ê·  ì¶”ë¡  ìŠ¤í…", f"{float(steps.float().mean()):.2f}")
